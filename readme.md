# ğŸš€ MLOps Pipeline - DetecciÃ³n de Fraude Financiero

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.0+-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

Proyecto MLOps completo para la detecciÃ³n de fraude en transacciones financieras. Implementa un pipeline end-to-end que incluye anÃ¡lisis exploratorio, ingenierÃ­a de caracterÃ­sticas, entrenamiento de modelos, despliegue via API REST y monitoreo de drift.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [Arquitectura](#-arquitectura)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n y ConfiguraciÃ³n](#-instalaciÃ³n-y-configuraciÃ³n)
- [Uso](#-uso)
- [Hallazgos del EDA](#-hallazgos-del-eda)
- [Modelos y Performance](#-modelos-y-performance)
- [API REST](#-api-rest)
- [Dashboard de Monitoreo](#-dashboard-de-monitoreo)
- [Docker](#-docker)
- [Contribuciones](#-contribuciones)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema completo de MLOps para detectar transacciones fraudulentas en un dataset de transacciones financieras. El sistema cubre todas las etapas del ciclo de vida de un modelo de Machine Learning:

### Caso de Negocio

Las instituciones financieras pierden miles de millones de dÃ³lares anualmente debido al fraude. Este proyecto proporciona una soluciÃ³n automatizada para:

- âœ… **Detectar transacciones fraudulentas** en tiempo real
- âœ… **Reducir falsos positivos** mediante modelos optimizados
- âœ… **Monitorear la calidad** de los datos en producciÃ³n
- âœ… **Escalar fÃ¡cilmente** mediante contenedores Docker

### CaracterÃ­sticas Principales

- ğŸ“Š **AnÃ¡lisis Exploratorio Completo**: Notebook interactivo con visualizaciones
- ğŸ” **ValidaciÃ³n de Datos**: Reglas de negocio automatizadas
- ğŸ› ï¸ **IngenierÃ­a de CaracterÃ­sticas**: Features derivados optimizados
- ğŸ¤– **MÃºltiples Modelos**: ComparaciÃ³n de LogisticRegression, RandomForest, XGBoost
- ğŸš€ **API REST**: Predicciones en tiempo real con FastAPI
- ğŸ“ˆ **Dashboard de Monitoreo**: DetecciÃ³n de data drift con Streamlit
- ğŸ³ **Dockerizado**: Despliegue sencillo en cualquier entorno

---

## ğŸ—ï¸ Arquitectura

El proyecto sigue una arquitectura modular basada en **clases e importaciones**, facilitando el mantenimiento y escalabilidad:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Source    â”‚
â”‚ (CSV Dataset)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DataLoader     â”‚â”€â”€â”€â”€â”€â–¶â”‚ DataValidator    â”‚
â”‚ (cargar_datos)  â”‚      â”‚ (data_validation)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FeatureEngineer â”‚
â”‚ (ft_engineering)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ModelTrainer   â”‚â”€â”€â”€â”€â”€â–¶â”‚  Best Model      â”‚
â”‚ (model_training)â”‚      â”‚  (best_model.    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   joblib)        â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                              â”‚
                  â–¼                              â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  FastAPI Server â”‚          â”‚    Streamlit    â”‚
         â”‚ (model_deploy)  â”‚          â”‚  (monitoring)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Trabajo

1. **Carga**: `DataLoader` lee el dataset y elimina columnas irrelevantes
2. **ValidaciÃ³n**: `DataValidator` verifica esquema, tipos y reglas de negocio
3. **IngenierÃ­a**: `FeatureEngineer` crea features, divide datos y preprocesa
4. **Entrenamiento**: `ModelTrainer` entrena mÃºltiples modelos y selecciona el mejor
5. **Despliegue**: API REST con FastAPI sirve predicciones
6. **Monitoreo**: Dashboard Streamlit detecta data drift

---

## ğŸ“ Estructura del Proyecto

```
mlops_pipeline/
â”‚
â”œâ”€â”€ mlops_pipeline/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ __init__.py                    # Paquete Python
â”‚       â”œâ”€â”€ config.py                      # ConfiguraciÃ³n centralizada
â”‚       â”œâ”€â”€ cargar_datos.py                # Clase DataLoader
â”‚       â”œâ”€â”€ data_validation.py             # Clase DataValidator
â”‚       â”œâ”€â”€ ft_engineering.py              # Clase FeatureEngineer
â”‚       â”œâ”€â”€ model_training_evaluation.py   # Clase ModelTrainer (orquestador)
â”‚       â”œâ”€â”€ model_deploy.py                # API REST con FastAPI
â”‚       â”œâ”€â”€ model_monitoring.py            # Dashboard con Streamlit
â”‚       â””â”€â”€ comprension_eda.ipynb          # Notebook de EDA
â”‚
â”œâ”€â”€ financial_fraud_dataset.csv            # Dataset principal
â”œâ”€â”€ best_model.joblib                      # Mejor modelo entrenado
â”œâ”€â”€ preprocessor.joblib                    # Pipeline de preprocesamiento
â”‚
â”œâ”€â”€ requirements.txt                       # Dependencias de Python
â”œâ”€â”€ config.json                            # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ setup.bat                              # Script de instalaciÃ³n (Windows)
â”œâ”€â”€ .gitignore                             # Archivos ignorados por Git
â”œâ”€â”€ Dockerfile                             # ConfiguraciÃ³n de contenedor
â””â”€â”€ README.md                              # Este archivo
```

---

## ğŸ”§ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Python 3.10 o superior
- pip (gestor de paquetes de Python)
- Git (opcional, para clonar el repositorio)

### OpciÃ³n 1: InstalaciÃ³n AutomÃ¡tica (Windows)

```batch
# Ejecutar el script de configuraciÃ³n
setup.bat
```

Este script:
- Crea un entorno virtual `mlops_pipeline-venv`
- Instala todas las dependencias
- Activa el entorno

### OpciÃ³n 2: InstalaciÃ³n Manual

```bash
# 1. Crear entorno virtual
python -m venv mlops_pipeline-venv

# 2. Activar el entorno
# Windows:
mlops_pipeline-venv\Scripts\activate
# Linux/Mac:
source mlops_pipeline-venv/bin/activate

# 3. Actualizar pip
pip install --upgrade pip

# 4. Instalar dependencias
pip install -r requirements.txt
```

### Verificar InstalaciÃ³n

```bash
python -c "import pandas, sklearn, fastapi, streamlit; print('âœ… InstalaciÃ³n exitosa')"
```

---

## ğŸš€ Uso

### ğŸ¯ OpciÃ³n Recomendada: MenÃº Interactivo

La forma mÃ¡s fÃ¡cil de usar el proyecto es con el menÃº interactivo:

```bash
python main.py
```

Esto abrirÃ¡ un menÃº con todas las opciones disponibles:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OPCIONES DISPONIBLES:                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. ğŸ“Š Ejecutar Pipeline Completo (E2E)                       â”‚
â”‚  2. ğŸ” Solo Validar Datos                                     â”‚
â”‚  3. ğŸ› ï¸  Solo IngenierÃ­a de CaracterÃ­sticas                    â”‚
â”‚  4. ğŸ¤– Solo Entrenar Modelos                                  â”‚
â”‚  5. ğŸŒ Iniciar API REST                                       â”‚
â”‚  6. ğŸ“ˆ Abrir Dashboard de Monitoreo                           â”‚
â”‚  7. ğŸ““ Abrir Notebook de EDA                                  â”‚
â”‚  8. â„¹ï¸  Ver InformaciÃ³n del Proyecto                          â”‚
â”‚  0. âŒ Salir                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. AnÃ¡lisis Exploratorio de Datos (EDA)

Ejecutar el notebook para entender el dataset:

```bash
jupyter lab mlops_pipeline/src/comprension_eda.ipynb
```

El notebook incluye:
- Carga de datos y exploraciÃ³n inicial
- AnÃ¡lisis univariable (histogramas, boxplots, estadÃ­sticas)
- AnÃ¡lisis bivariable y multivariable (correlaciones, pairplots)
- IdentificaciÃ³n de reglas de validaciÃ³n
- Propuesta de features derivados

### 2. Entrenar el Pipeline Completo

Ejecutar el orquestador que realiza todo el flujo E2E:

```bash
python -m mlops_pipeline.src.model_training_evaluation
```

Este comando:
1. âœ… Carga los datos
2. âœ… Valida la calidad e integridad
3. âœ… Aplica ingenierÃ­a de caracterÃ­sticas
4. âœ… Entrena mÃºltiples modelos (LogisticRegression, RandomForest, XGBoost)
5. âœ… Compara performance y selecciona el mejor
6. âœ… Guarda el modelo y preprocesador

**Salida esperada:**
- `best_model.joblib`: Modelo entrenado
- `preprocessor.joblib`: Pipeline de preprocesamiento
- GrÃ¡ficos comparativos (matrices de confusiÃ³n, curvas ROC)

### 3. Probar MÃ³dulos Individuales

```bash
# Probar carga de datos
python -m mlops_pipeline.src.cargar_datos

# Probar validaciÃ³n
python -m mlops_pipeline.src.data_validation

# Probar ingenierÃ­a de caracterÃ­sticas
python -m mlops_pipeline.src.ft_engineering
```

### 4. Desplegar la API REST

```bash
python -m mlops_pipeline.src.model_deploy
```

La API estarÃ¡ disponible en:
- **URL Base**: http://localhost:8000
- **DocumentaciÃ³n Interactiva**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

#### Endpoints Disponibles

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/` | GET | InformaciÃ³n de la API |
| `/health` | GET | Estado de salud del servicio |
| `/predict` | POST | PredicciÃ³n para una transacciÃ³n |
| `/predict/batch` | POST | Predicciones por lote |
| `/model/info` | GET | InformaciÃ³n del modelo |

#### Ejemplo de Uso (cURL)

```bash
# PredicciÃ³n individual
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "amount": 9000.60,
    "oldbalanceOrg": 170136.0,
    "newbalanceOrg": 161136.0,
    "type": "TRANSFER"
  }'
```

#### Ejemplo de Uso (Python)

```python
import requests

url = "http://localhost:8000/predict"
transaction = {
    "amount": 9000.60,
    "oldbalanceOrg": 170136.0,
    "newbalanceOrg": 161136.0,
    "type": "TRANSFER"
}

response = requests.post(url, json=transaction)
print(response.json())
# Output: {"index": 0, "is_fraud": 0, "fraud_probability": 0.0234, "risk_level": "Bajo", ...}
```

### 5. Lanzar el Dashboard de Monitoreo

```bash
streamlit run mlops_pipeline/src/model_monitoring.py
```

El dashboard abrirÃ¡ automÃ¡ticamente en el navegador (http://localhost:8501).

**Funcionalidades:**
- ğŸ“Š ComparaciÃ³n de distribuciones (baseline vs producciÃ³n)
- ğŸ” Test estadÃ­sticos de drift (KS para numÃ©ricas, ChiÂ² para categÃ³ricas)
- ğŸ“ˆ Visualizaciones interactivas
- âš ï¸ Alertas automÃ¡ticas de drift
- ğŸ’¡ Recomendaciones de re-entrenamiento

---

## ğŸ“Š Hallazgos del EDA

### 1. Desbalanceo de Clases

- **No Fraude**: ~99%
- **Fraude**: ~1%
- **Ratio**: 1:100

**AcciÃ³n tomada**: AplicaciÃ³n de `RandomUnderSampler` y `class_weight='balanced'`

### 2. Variables NumÃ©ricas

| Variable | Media | Mediana | Skewness | Outliers |
|----------|-------|---------|----------|----------|
| `amount` | 179,862 | 74,871 | 2.45 | âš ï¸ Alto |
| `oldbalanceOrg` | 833,883 | 14,208 | 5.12 | âš ï¸ Alto |
| `newbalanceOrg` | 855,114 | 0 | 4.98 | âš ï¸ Alto |

**Observaciones:**
- Distribuciones altamente asimÃ©tricas (right-skewed)
- Presencia significativa de outliers
- Se aplicÃ³ **StandardScaler** para normalizaciÃ³n

### 3. Tipo de TransacciÃ³n

| Tipo | % del Total | % de Fraude |
|------|-------------|-------------|
| CASH_OUT | 35% | ğŸ”´ Alto |
| PAYMENT | 34% | ğŸŸ¢ Bajo |
| CASH_IN | 22% | ğŸŸ¢ Muy Bajo |
| TRANSFER | 8% | ğŸ”´ Alto |
| DEBIT | 1% | ğŸŸ¢ Bajo |

**ConclusiÃ³n**: `CASH_OUT` y `TRANSFER` son indicadores fuertes de fraude

### 4. Reglas de ValidaciÃ³n Identificadas

1. âœ… `amount >= 0`
2. âœ… `type` âˆˆ {CASH_IN, CASH_OUT, DEBIT, PAYMENT, TRANSFER}
3. âœ… `isFraud` âˆˆ {0, 1}
4. âœ… Balances no negativos

### 5. Features Derivados Creados

| Feature | FÃ³rmula | PropÃ³sito |
|---------|---------|-----------|
| `errorBalanceOrg` | `oldbalanceOrg - newbalanceOrg - amount` | Detecta inconsistencias |
| `transactionRatio` | `amount / (oldbalanceOrg + 1)` | Identifica transacciones desproporcionadas |
| `zeroBalanceAfter` | `1 if newbalanceOrg == 0 else 0` | Marca cuentas vaciadas |

---

## ğŸ¤– Modelos y Performance

### Modelos Entrenados

1. **Logistic Regression**
   - Baseline simple y rÃ¡pido
   - Interpretable

2. **Random Forest**
   - Manejo automÃ¡tico de no-linealidades
   - Feature importance

3. **XGBoost**
   - Estado del arte en datos tabulares
   - OptimizaciÃ³n de gradiente

### MÃ©tricas de EvaluaciÃ³n

Dado el desbalanceo, se priorizan:
- **ROC-AUC**: MÃ©trica principal de comparaciÃ³n
- **Recall**: Minimizar fraudes no detectados (falsos negativos)
- **Precision**: Reducir falsos positivos
- **F1-Score**: Balance entre precision y recall

### Resultados Esperados

| Modelo | ROC-AUC | F1-Score | Recall | Precision |
|--------|---------|----------|--------|-----------|
| Logistic Regression | ~0.85 | ~0.75 | ~0.72 | ~0.78 |
| Random Forest | ~0.92 | ~0.85 | ~0.83 | ~0.87 |
| **XGBoost** | **~0.95** | **~0.89** | **~0.88** | **~0.91** |

*Nota: Los valores exactos dependen del dataset y semilla aleatoria*

### SelecciÃ³n del Modelo

El modelo con el **mayor ROC-AUC** se guarda automÃ¡ticamente como `best_model.joblib`.

---

## ğŸŒ API REST

### Arquitectura de la API

- **Framework**: FastAPI (alta performance, validaciÃ³n automÃ¡tica)
- **ValidaciÃ³n**: Pydantic models
- **DocumentaciÃ³n**: Auto-generada (OpenAPI/Swagger)

### Modelos de Datos (Schemas)

```python
class Transaction(BaseModel):
    amount: float
    oldbalanceOrg: float
    newbalanceOrg: float
    type: str  # CASH_IN, CASH_OUT, DEBIT, PAYMENT, TRANSFER

class PredictionResponse(BaseModel):
    index: int
    is_fraud: int  # 0 o 1
    fraud_probability: float  # 0.0 - 1.0
    risk_level: str  # "Bajo", "Medio", "Alto"
    timestamp: str
```

### Ejemplo de Respuesta

```json
{
  "index": 0,
  "is_fraud": 1,
  "fraud_probability": 0.8745,
  "risk_level": "Alto",
  "timestamp": "2025-11-09T10:30:45.123456"
}
```

### Escalabilidad

- **Procesamiento por lotes**: Endpoint `/predict/batch` para mÃºltiples transacciones
- **Async/Await**: Soporte para alta concurrencia
- **Caching**: Posibilidad de agregar Redis para cachÃ© de predicciones

---

## ğŸ“ˆ Dashboard de Monitoreo

### Funcionalidades del Dashboard

1. **Carga de Datos**
   - Upload de CSV con datos de producciÃ³n
   - ComparaciÃ³n automÃ¡tica con baseline

2. **DetecciÃ³n de Drift**
   - **Variables NumÃ©ricas**: Test de Kolmogorov-Smirnov
   - **Variables CategÃ³ricas**: Test de Chi-Cuadrado

3. **Visualizaciones**
   - GrÃ¡ficos KDE comparativos
   - Heatmaps de frecuencias
   - Tablas de contingencia

4. **Alertas AutomÃ¡ticas**
   - ğŸŸ¢ Verde: Sin drift detectado
   - ğŸ”´ Rojo: Drift significativo (requiere acciÃ³n)

5. **Recomendaciones**
   - Sugerencias de re-entrenamiento
   - InvestigaciÃ³n de causas
   - ConfiguraciÃ³n de alertas

### InterpretaciÃ³n de Resultados

| P-Value | InterpretaciÃ³n | AcciÃ³n |
|---------|----------------|--------|
| p > 0.05 | No hay drift | âœ… Continuar monitoreando |
| p < 0.05 | **Drift detectado** | âš ï¸ Investigar y considerar re-entrenamiento |
| p < 0.01 | Drift severo | ğŸš¨ Re-entrenar urgentemente |

---

## ğŸ³ Docker

### ConstrucciÃ³n de la Imagen

```bash
docker build -t fraud-detection-api .
```

### EjecuciÃ³n del Contenedor

```bash
docker run -d \
  --name fraud-api \
  -p 8000:8000 \
  -v $(pwd)/best_model.joblib:/app/best_model.joblib \
  -v $(pwd)/preprocessor.joblib:/app/preprocessor.joblib \
  fraud-detection-api
```

### Verificar Estado

```bash
# Logs
docker logs fraud-api

# Health check
curl http://localhost:8000/health
```

### Docker Compose (Opcional)

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./best_model.joblib:/app/best_model.joblib
      - ./preprocessor.joblib:/app/preprocessor.joblib
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
```

Ejecutar:
```bash
docker-compose up -d
```

---

## ğŸ“ Ejemplos de Uso

En la carpeta `examples/` encontrarÃ¡s scripts completos que demuestran cÃ³mo usar el proyecto:

### 1. Uso de la API REST

```bash
python examples/api_usage_example.py
```

Este script muestra:
- âœ… CÃ³mo verificar el estado de la API
- âœ… CÃ³mo hacer predicciones individuales
- âœ… CÃ³mo hacer predicciones por lote
- âœ… Ejemplos de transacciones normales y sospechosas

### 2. Uso ProgramÃ¡tico del Pipeline

```bash
python examples/pipeline_usage_example.py
```

Este script demuestra:
- âœ… Uso modular de cada componente
- âœ… Pipeline completo E2E
- âœ… CÃ³mo personalizar el flujo

Consulta [`examples/README.md`](examples/README.md) para mÃ¡s detalles.

---

## ğŸ§ª Testing

### Ejecutar Validaciones

```bash
# Validar carga de datos
python -m mlops_pipeline.src.cargar_datos

# Validar pipeline completo
python -m mlops_pipeline.src.data_validation
```

### Test de API

```bash
# Health check
curl http://localhost:8000/health

# PredicciÃ³n de prueba
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"amount": 5000, "oldbalanceOrg": 10000, "newbalanceOrg": 5000, "type": "TRANSFER"}'
```

---

## ğŸ“ PrÃ³ximos Pasos y Mejoras

### Corto Plazo
- [ ] Implementar CI/CD con GitHub Actions
- [ ] Agregar tests unitarios (pytest)
- [ ] Configurar logging centralizado

### Mediano Plazo
- [ ] OptimizaciÃ³n de hiperparÃ¡metros (Optuna, GridSearch)
- [ ] Feature selection automÃ¡tico (SHAP values)
- [ ] Versionado de modelos (MLflow, DVC)

### Largo Plazo
- [ ] Despliegue en cloud (AWS, Azure, GCP)
- [ ] Auto-retraining periÃ³dico
- [ ] Monitoreo de performance en producciÃ³n (A/B testing)

---

## ğŸ‘¥ Contribuciones

Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ“ Contacto

**Proyecto desarrollado como parte del curso de MLOps**

- ğŸ“§ Email: [tu-email@example.com](mailto:tu-email@example.com)
- ğŸ”— LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)
- ğŸ™ GitHub: [@tu-usuario](https://github.com/tu-usuario)

---

## ğŸ™ Agradecimientos

- Dataset: [Kaggle - Financial Fraud Detection](https://www.kaggle.com/)
- Frameworks: FastAPI, Streamlit, Scikit-learn, XGBoost
- Comunidad: Stack Overflow, Medium, GitHub

---

<div align="center">
  <p><strong>â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub!</strong></p>
  <p>Hecho con â¤ï¸ y â˜•</p>
</div>
