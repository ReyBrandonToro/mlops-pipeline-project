# üöÄ MLOps Pipeline - Detecci√≥n de Fraude Financiero

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.0+-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

Proyecto MLOps completo para la detecci√≥n de fraude en transacciones financieras. Implementa un pipeline end-to-end que incluye an√°lisis exploratorio, ingenier√≠a de caracter√≠sticas, entrenamiento de modelos, despliegue via API REST y monitoreo de drift.

## üìã Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Arquitectura](#-arquitectura)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Instalaci√≥n y Configuraci√≥n](#-instalaci√≥n-y-configuraci√≥n)
- [Uso](#-uso)
- [Hallazgos del EDA](#-hallazgos-del-eda)
- [Modelos y Performance](#-modelos-y-performance)
- [API REST](#-api-rest)
- [Dashboard de Monitoreo](#-dashboard-de-monitoreo)
- [Docker](#-docker)
- [Contribuciones](#-contribuciones)

---

## üéØ Descripci√≥n del Proyecto

Este proyecto implementa un sistema completo de MLOps para detectar transacciones fraudulentas en un dataset de transacciones financieras. El sistema cubre todas las etapas del ciclo de vida de un modelo de Machine Learning:

### Caso de Negocio

Las instituciones financieras pierden miles de millones de d√≥lares anualmente debido al fraude. Este proyecto proporciona una soluci√≥n automatizada para:

- ‚úÖ **Detectar transacciones fraudulentas** en tiempo real
- ‚úÖ **Reducir falsos positivos** mediante modelos optimizados
- ‚úÖ **Monitorear la calidad** de los datos en producci√≥n
- ‚úÖ **Escalar f√°cilmente** mediante contenedores Docker

### Caracter√≠sticas Principales

- üìä **An√°lisis Exploratorio Completo**: Notebook interactivo con visualizaciones
- üîç **Validaci√≥n de Datos**: Reglas de negocio automatizadas
- üõ†Ô∏è **Ingenier√≠a de Caracter√≠sticas**: Features derivados optimizados
- ü§ñ **M√∫ltiples Modelos**: Comparaci√≥n de LogisticRegression, RandomForest, XGBoost
- üöÄ **API REST**: Predicciones en tiempo real con FastAPI
- üìà **Dashboard de Monitoreo**: Detecci√≥n de data drift con Streamlit
- üê≥ **Dockerizado**: Despliegue sencillo en cualquier entorno

---

## üèóÔ∏è Arquitectura

El proyecto sigue una arquitectura modular basada en **clases e importaciones**, facilitando el mantenimiento y escalabilidad:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Data Source    ‚îÇ
‚îÇ (CSV Dataset)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  DataLoader     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ DataValidator    ‚îÇ
‚îÇ (cargar_datos)  ‚îÇ      ‚îÇ (data_validation)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FeatureEngineer ‚îÇ
‚îÇ (ft_engineering)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ModelTrainer   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Best Model      ‚îÇ
‚îÇ (model_training)‚îÇ      ‚îÇ  (best_model.    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ   joblib)        ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ                              ‚îÇ
                  ‚ñº                              ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  FastAPI Server ‚îÇ          ‚îÇ    Streamlit    ‚îÇ
         ‚îÇ (model_deploy)  ‚îÇ          ‚îÇ  (monitoring)   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Trabajo

1. **Carga**: `DataLoader` lee el dataset y elimina columnas irrelevantes
2. **Validaci√≥n**: `DataValidator` verifica esquema, tipos y reglas de negocio
3. **Ingenier√≠a**: `FeatureEngineer` crea features, divide datos y preprocesa
4. **Entrenamiento**: `ModelTrainer` entrena m√∫ltiples modelos y selecciona el mejor
5. **Despliegue**: API REST con FastAPI sirve predicciones
6. **Monitoreo**: Dashboard Streamlit detecta data drift

---

## üìÅ Estructura del Proyecto

```
mlops_pipeline/
‚îÇ
‚îú‚îÄ‚îÄ mlops_pipeline/
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py                    # Paquete Python
‚îÇ       ‚îú‚îÄ‚îÄ config.py                      # Configuraci√≥n centralizada
‚îÇ       ‚îú‚îÄ‚îÄ cargar_datos.py                # Clase DataLoader
‚îÇ       ‚îú‚îÄ‚îÄ data_validation.py             # Clase DataValidator
‚îÇ       ‚îú‚îÄ‚îÄ ft_engineering.py              # Clase FeatureEngineer
‚îÇ       ‚îú‚îÄ‚îÄ model_training_evaluation.py   # Clase ModelTrainer (orquestador)
‚îÇ       ‚îú‚îÄ‚îÄ model_deploy.py                # API REST con FastAPI
‚îÇ       ‚îú‚îÄ‚îÄ model_monitoring.py            # Dashboard con Streamlit
‚îÇ       ‚îî‚îÄ‚îÄ comprension_eda.ipynb          # Notebook de EDA
‚îÇ
‚îú‚îÄ‚îÄ financial_fraud_dataset.csv            # Dataset principal
‚îú‚îÄ‚îÄ best_model.joblib                      # Mejor modelo entrenado
‚îú‚îÄ‚îÄ preprocessor.joblib                    # Pipeline de preprocesamiento
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                       # Dependencias de Python
‚îú‚îÄ‚îÄ config.json                            # Configuraci√≥n del proyecto
‚îú‚îÄ‚îÄ setup.bat                              # Script de instalaci√≥n (Windows)
‚îú‚îÄ‚îÄ .gitignore                             # Archivos ignorados por Git
‚îú‚îÄ‚îÄ Dockerfile                             # Configuraci√≥n de contenedor
‚îî‚îÄ‚îÄ README.md                              # Este archivo
```

---

## üîß Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

- Python 3.10 o superior
- pip (gestor de paquetes de Python)
- Git (opcional, para clonar el repositorio)

### Opci√≥n 1: Instalaci√≥n Autom√°tica (Windows)

```batch
# Ejecutar el script de configuraci√≥n
setup.bat
```

Este script:
- Crea un entorno virtual `mlops_pipeline-venv`
- Instala todas las dependencias
- Activa el entorno

### Opci√≥n 2: Instalaci√≥n Manual

```bash
# 1. Crear entorno virtual
python -m venv mlops_pipeline-venv

# 2. Activar el entorno
# Windows:
mlops_pipeline-venv\Scripts\activate
# Linux/Mac:
source mlops_pipeline-venv/bin/activate

# 3. Actualizar pip
pip install --upgrade pip

# 4. Instalar dependencias
pip install -r requirements.txt
```

### Verificar Instalaci√≥n

```bash
python -c "import pandas, sklearn, fastapi, streamlit; print('‚úÖ Instalaci√≥n exitosa')"
```

---

## üöÄ Uso

### üéØ Opci√≥n Recomendada: Men√∫ Interactivo

La forma m√°s f√°cil de usar el proyecto es con el men√∫ interactivo:

```bash
python main.py
```

Esto abrir√° un men√∫ con todas las opciones disponibles:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OPCIONES DISPONIBLES:                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. üìä Ejecutar Pipeline Completo (E2E)                       ‚îÇ
‚îÇ  2. üîç Solo Validar Datos                                     ‚îÇ
‚îÇ  3. üõ†Ô∏è  Solo Ingenier√≠a de Caracter√≠sticas                    ‚îÇ
‚îÇ  4. ü§ñ Solo Entrenar Modelos                                  ‚îÇ
‚îÇ  5. üåê Iniciar API REST                                       ‚îÇ
‚îÇ  6. üìà Abrir Dashboard de Monitoreo                           ‚îÇ
‚îÇ  7. üìì Abrir Notebook de EDA                                  ‚îÇ
‚îÇ  8. ‚ÑπÔ∏è  Ver Informaci√≥n del Proyecto                          ‚îÇ
‚îÇ  0. ‚ùå Salir                                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1. An√°lisis Exploratorio de Datos (EDA)

Ejecutar el notebook para entender el dataset:

```bash
jupyter lab mlops_pipeline/src/comprension_eda.ipynb
```

El notebook incluye:
- Carga de datos y exploraci√≥n inicial
- An√°lisis univariable (histogramas, boxplots, estad√≠sticas)
- An√°lisis bivariable y multivariable (correlaciones, pairplots)
- Identificaci√≥n de reglas de validaci√≥n
- Propuesta de features derivados

### 2. Entrenar el Pipeline Completo

Ejecutar el orquestador que realiza todo el flujo E2E:

```bash
python -m mlops_pipeline.src.model_training_evaluation
```

Este comando:
1. ‚úÖ Carga los datos
2. ‚úÖ Valida la calidad e integridad
3. ‚úÖ Aplica ingenier√≠a de caracter√≠sticas
4. ‚úÖ Entrena m√∫ltiples modelos (LogisticRegression, RandomForest, XGBoost)
5. ‚úÖ Compara performance y selecciona el mejor
6. ‚úÖ Guarda el modelo y preprocesador

**Salida esperada:**
- `best_model.joblib`: Modelo entrenado
- `preprocessor.joblib`: Pipeline de preprocesamiento
- Gr√°ficos comparativos (matrices de confusi√≥n, curvas ROC)

### 3. Probar M√≥dulos Individuales

```bash
# Probar carga de datos
python -m mlops_pipeline.src.cargar_datos

# Probar validaci√≥n
python -m mlops_pipeline.src.data_validation

# Probar ingenier√≠a de caracter√≠sticas
python -m mlops_pipeline.src.ft_engineering
```

### 4. Desplegar la API REST

```bash
python -m mlops_pipeline.src.model_deploy
```

La API estar√° disponible en:
- **URL Base**: http://localhost:8000
- **Documentaci√≥n Interactiva**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

#### Endpoints Disponibles

| Endpoint | M√©todo | Descripci√≥n |
|----------|--------|-------------|
| `/` | GET | Informaci√≥n de la API |
| `/health` | GET | Estado de salud del servicio |
| `/predict` | POST | Predicci√≥n para una transacci√≥n |
| `/predict/batch` | POST | Predicciones por lote |
| `/model/info` | GET | Informaci√≥n del modelo |

#### Ejemplo de Uso (cURL)

```bash
# Predicci√≥n individual
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "amount": 9000.60,
    "oldbalanceOrg": 170136.0,
    "newbalanceOrg": 161136.0,
    "type": "TRANSFER"
  }'
```

#### Ejemplo de Uso (Python)

```python
import requests

url = "http://localhost:8000/predict"
transaction = {
    "amount": 9000.60,
    "oldbalanceOrg": 170136.0,
    "newbalanceOrg": 161136.0,
    "type": "TRANSFER"
}

response = requests.post(url, json=transaction)
print(response.json())
# Output: {"index": 0, "is_fraud": 0, "fraud_probability": 0.0234, "risk_level": "Bajo", ...}
```

### 5. Lanzar el Dashboard de Monitoreo

```bash
streamlit run mlops_pipeline/src/model_monitoring.py
```

El dashboard abrir√° autom√°ticamente en el navegador (http://localhost:8501).

**Funcionalidades:**
- üìä Comparaci√≥n de distribuciones (baseline vs producci√≥n)
- üîç Test estad√≠sticos de drift (KS para num√©ricas, Chi¬≤ para categ√≥ricas)
- üìà Visualizaciones interactivas
- ‚ö†Ô∏è Alertas autom√°ticas de drift
- üí° Recomendaciones de re-entrenamiento

---

## üìä Hallazgos del EDA

### 1. Desbalanceo de Clases

- **No Fraude**: ~99%
- **Fraude**: ~1%
- **Ratio**: 1:100

**Acci√≥n tomada**: Aplicaci√≥n de `RandomUnderSampler` y `class_weight='balanced'`

### 2. Variables Num√©ricas

| Variable | Media | Mediana | Skewness | Outliers |
|----------|-------|---------|----------|----------|
| `amount` | 179,862 | 74,871 | 2.45 | ‚ö†Ô∏è Alto |
| `oldbalanceOrg` | 833,883 | 14,208 | 5.12 | ‚ö†Ô∏è Alto |
| `newbalanceOrg` | 855,114 | 0 | 4.98 | ‚ö†Ô∏è Alto |

**Observaciones:**
- Distribuciones altamente asim√©tricas (right-skewed)
- Presencia significativa de outliers
- Se aplic√≥ **StandardScaler** para normalizaci√≥n

### 3. Tipo de Transacci√≥n

| Tipo | % del Total | % de Fraude |
|------|-------------|-------------|
| CASH_OUT | 35% | üî¥ Alto |
| PAYMENT | 34% | üü¢ Bajo |
| CASH_IN | 22% | üü¢ Muy Bajo |
| TRANSFER | 8% | üî¥ Alto |
| DEBIT | 1% | üü¢ Bajo |

**Conclusi√≥n**: `CASH_OUT` y `TRANSFER` son indicadores fuertes de fraude

### 4. Reglas de Validaci√≥n Identificadas

1. ‚úÖ `amount >= 0`
2. ‚úÖ `type` ‚àà {CASH_IN, CASH_OUT, DEBIT, PAYMENT, TRANSFER}
3. ‚úÖ `isFraud` ‚àà {0, 1}
4. ‚úÖ Balances no negativos

### 5. Features Derivados Creados

| Feature | F√≥rmula | Prop√≥sito |
|---------|---------|-----------|
| `errorBalanceOrg` | `oldbalanceOrg - newbalanceOrg - amount` | Detecta inconsistencias |
| `transactionRatio` | `amount / (oldbalanceOrg + 1)` | Identifica transacciones desproporcionadas |
| `zeroBalanceAfter` | `1 if newbalanceOrg == 0 else 0` | Marca cuentas vaciadas |

---

## ü§ñ Modelos y Performance

### Modelos Entrenados

1. **Logistic Regression**
   - Baseline simple y r√°pido
   - Interpretable

2. **Random Forest**
   - Manejo autom√°tico de no-linealidades
   - Feature importance

3. **XGBoost**
   - Estado del arte en datos tabulares
   - Optimizaci√≥n de gradiente

### M√©tricas de Evaluaci√≥n

Dado el desbalanceo, se priorizan:
- **ROC-AUC**: M√©trica principal de comparaci√≥n
- **Recall**: Minimizar fraudes no detectados (falsos negativos)
- **Precision**: Reducir falsos positivos
- **F1-Score**: Balance entre precision y recall

### Resultados Esperados

| Modelo | ROC-AUC | F1-Score | Recall | Precision |
|--------|---------|----------|--------|-----------|
| Logistic Regression | ~0.85 | ~0.75 | ~0.72 | ~0.78 |
| Random Forest | ~0.92 | ~0.85 | ~0.83 | ~0.87 |
| **XGBoost** | **~0.95** | **~0.89** | **~0.88** | **~0.91** |

*Nota: Los valores exactos dependen del dataset y semilla aleatoria*

### Selecci√≥n del Modelo

El modelo con el **mayor ROC-AUC** se guarda autom√°ticamente como `best_model.joblib`.

---

## üåê API REST

### Arquitectura de la API

- **Framework**: FastAPI (alta performance, validaci√≥n autom√°tica)
- **Validaci√≥n**: Pydantic models
- **Documentaci√≥n**: Auto-generada (OpenAPI/Swagger)

### Modelos de Datos (Schemas)

```python
class Transaction(BaseModel):
    amount: float
    oldbalanceOrg: float
    newbalanceOrg: float
    type: str  # CASH_IN, CASH_OUT, DEBIT, PAYMENT, TRANSFER

class PredictionResponse(BaseModel):
    index: int
    is_fraud: int  # 0 o 1
    fraud_probability: float  # 0.0 - 1.0
    risk_level: str  # "Bajo", "Medio", "Alto"
    timestamp: str
```

### Ejemplo de Respuesta

```json
{
  "index": 0,
  "is_fraud": 1,
  "fraud_probability": 0.8745,
  "risk_level": "Alto",
  "timestamp": "2025-11-09T10:30:45.123456"
}
```

### Escalabilidad

- **Procesamiento por lotes**: Endpoint `/predict/batch` para m√∫ltiples transacciones
- **Async/Await**: Soporte para alta concurrencia
- **Caching**: Posibilidad de agregar Redis para cach√© de predicciones

---

## üìà Dashboard de Monitoreo

### Funcionalidades del Dashboard

1. **Carga de Datos**
   - Upload de CSV con datos de producci√≥n
   - Comparaci√≥n autom√°tica con baseline

2. **Detecci√≥n de Drift**
   - **Variables Num√©ricas**: Test de Kolmogorov-Smirnov
   - **Variables Categ√≥ricas**: Test de Chi-Cuadrado

3. **Visualizaciones**
   - Gr√°ficos KDE comparativos
   - Heatmaps de frecuencias
   - Tablas de contingencia

4. **Alertas Autom√°ticas**
   - üü¢ Verde: Sin drift detectado
   - üî¥ Rojo: Drift significativo (requiere acci√≥n)

5. **Recomendaciones**
   - Sugerencias de re-entrenamiento
   - Investigaci√≥n de causas
   - Configuraci√≥n de alertas

### Interpretaci√≥n de Resultados

| P-Value | Interpretaci√≥n | Acci√≥n |
|---------|----------------|--------|
| p > 0.05 | No hay drift | ‚úÖ Continuar monitoreando |
| p < 0.05 | **Drift detectado** | ‚ö†Ô∏è Investigar y considerar re-entrenamiento |
| p < 0.01 | Drift severo | üö® Re-entrenar urgentemente |

---

## üê≥ Docker

### Construcci√≥n de la Imagen

```bash
docker build -t fraud-detection-api .
```

### Ejecuci√≥n del Contenedor

```bash
docker run -d \
  --name fraud-api \
  -p 8000:8000 \
  -v $(pwd)/best_model.joblib:/app/best_model.joblib \
  -v $(pwd)/preprocessor.joblib:/app/preprocessor.joblib \
  fraud-detection-api
```

### Verificar Estado

```bash
# Logs
docker logs fraud-api

# Health check
curl http://localhost:8000/health
```

### Docker Compose (Opcional)

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./best_model.joblib:/app/best_model.joblib
      - ./preprocessor.joblib:/app/preprocessor.joblib
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
```

Ejecutar:
```bash
docker-compose up -d
```

---

## üìÅ Ejemplos de Uso

En la carpeta `examples/` encontrar√°s scripts completos que demuestran c√≥mo usar el proyecto:

### 1. Uso de la API REST

```bash
python examples/api_usage_example.py
```

Este script muestra:
- ‚úÖ C√≥mo verificar el estado de la API
- ‚úÖ C√≥mo hacer predicciones individuales
- ‚úÖ C√≥mo hacer predicciones por lote
- ‚úÖ Ejemplos de transacciones normales y sospechosas

### 2. Uso Program√°tico del Pipeline

```bash
python examples/pipeline_usage_example.py
```

Este script demuestra:
- ‚úÖ Uso modular de cada componente
- ‚úÖ Pipeline completo E2E
- ‚úÖ C√≥mo personalizar el flujo

Consulta [`examples/README.md`](examples/README.md) para m√°s detalles.

---

## üß™ Testing

### Ejecutar Validaciones

```bash
# Validar carga de datos
python -m mlops_pipeline.src.cargar_datos

# Validar pipeline completo
python -m mlops_pipeline.src.data_validation
```

### Test de API

```bash
# Health check
curl http://localhost:8000/health

# Predicci√≥n de prueba
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"amount": 5000, "oldbalanceOrg": 10000, "newbalanceOrg": 5000, "type": "TRANSFER"}'
```

---

## üìù Pr√≥ximos Pasos y Mejoras

### Corto Plazo
- [ ] Implementar CI/CD con GitHub Actions
- [ ] Agregar tests unitarios (pytest)
- [ ] Configurar logging centralizado

### Mediano Plazo
- [ ] Optimizaci√≥n de hiperpar√°metros (Optuna, GridSearch)
- [ ] Feature selection autom√°tico (SHAP values)
- [ ] Versionado de modelos (MLflow, DVC)

### Largo Plazo
- [ ] Despliegue en cloud (AWS, Azure, GCP)
- [ ] Auto-retraining peri√≥dico
- [ ] Monitoreo de performance en producci√≥n (A/B testing)

---

## üë• Contribuciones

Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

---

## üìû Contacto

**Proyecto desarrollado como parte del curso de MLOps**

- üìß Email: [tu-email@example.com](mailto:tu-email@example.com)
- üîó LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)
- üêô GitHub: [@tu-usuario](https://github.com/tu-usuario)

---

## üôè Agradecimientos

- Dataset: [Kaggle - Financial Fraud Detection](https://www.kaggle.com/)
- Frameworks: FastAPI, Streamlit, Scikit-learn, XGBoost
- Comunidad: Stack Overflow, Medium, GitHub

---

<div align="center">
  <p><strong>‚≠ê Si este proyecto te fue √∫til, considera darle una estrella en GitHub!</strong></p>
  <p>Hecho con ‚ù§Ô∏è y ‚òï</p>
</div>

---

"Prueba SonarCloud"
